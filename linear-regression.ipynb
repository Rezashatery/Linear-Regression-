{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Linear Regression Example\n",
    "The example below uses a [marketing](https://scikit-learn.org/stable/datasets/toy_dataset.html) dataset,\n",
    "in order to illustrate a linear regression activity.\n",
    "\n",
    "Workflow:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Second experiment: compute the regression considering all the predicting variables \n",
    "    - Repeat the steps \n",
    "1. Third experiment:  \n",
    "    - Fit the tree using the default hyperparameters, in order to find the \n",
    "    maximum depth of the unconstrained tree\n",
    "    - Use *cross-validation* to find the optimal *maximum depth* of the tree\n",
    "    - Fit the tree with the optmal `max_depth`\n",
    "    - Predict and show the *root mean squared error*\n",
    "\n",
    "1. Fourth experiment: use the RandomForestRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Preparation\n",
    "    1. Load the dataset from a `.csv` file and show a short description\n",
    "    1. Show the two dimensional scatter plots for all the predicting variables with respect to the target\n",
    "    1. Split the data into *predicting variables* `X` and *target* `y`\n",
    "        1. here we set the `random_state` variable to make the experiment *repeatable* \n",
    "1. First experiment: compute the regression on a single predicting variable\n",
    "    1. Consider a reduced dataset containing the chosen variable and the target\n",
    "    1. Fit the `LinearRegression` estimator on the training set\n",
    "    1. Show the statistical significance of the fitted model\n",
    "    1. Predict the target for the test set using the *fitted* estimator\n",
    "    1. Compute the regression coefficients and the quality measures: *Root Mean Squared Error (RMSE)* and *coefficient of determination (r2)*\n",
    "1. Second experiment: compute the regression considering all the predicting variables\n",
    "    1. Repeat the steps \n",
    "1. Third experiment: use the `DecisionTreeRegressor` with the entire dataset\n",
    "    1. Fit the tree using the default hyperparameters, in order to find the \n",
    "    maximum depth of the unconstrained tree\n",
    "    1. Use *cross-validation* to find the optimal *maximum depth* of the tree\n",
    "    1. Fit the tree with the optmal `max_depth`\n",
    "    1. Predict and show the *root mean squared error*\n",
    "1. Fourth experiment: use the `RandomForestRegressor`\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code source: Claudio Sartori \n",
    "# License: BSD 3 clause\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy.stats\n",
    "from sklearn import datasets, linear_model\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import pandas as pd\n",
    "random_state = 94922767 # this will be used to guarantee the repeatability of the experiment"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpu_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
